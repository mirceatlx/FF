{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164a8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from ff import FF\n",
    "from data import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60271c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 32\n",
    "batch_size_test = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80f3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./datasets/MNIST/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f0f5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./datasets/MNIST/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b3306d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"in_dims\": [784, 500, 500],\n",
    "    \"out_dims\": [500, 500, 500],\n",
    "    \"epochs\": 50,\n",
    "    \"threshold\": 1.5,\n",
    "}\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bac009c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FF(num_layers, config, torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f16048",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8904549996058146\n",
      "0.7119278844197591\n",
      "0.6968376847108205\n",
      "0.6945142245292665\n",
      "0.6943762091795603\n",
      "0.6944306111335754\n",
      "0.6936002266407013\n",
      "0.6934893743197122\n",
      "0.6935726590951283\n",
      "0.6935866951942443\n",
      "0.693378122250239\n",
      "0.693519124587377\n",
      "0.6930455636978149\n",
      "0.6933305589358012\n",
      "0.6929041004180908\n",
      "0.6933121689160665\n",
      "0.6935051433245341\n",
      "0.6932327262560527\n",
      "0.6926033023993176\n",
      "0.6925544202327728\n",
      "0.6914953148365021\n",
      "0.6903269414107006\n",
      "0.6906576192378998\n",
      "0.6894031997521718\n",
      "0.687938203016917\n",
      "0.6886534182230631\n",
      "0.6881546227137249\n",
      "0.6873592774073284\n",
      "0.6856378269195557\n",
      "0.6850971853733062\n",
      "0.6850525907675425\n",
      "0.6903017214934031\n",
      "0.6832916494210561\n",
      "0.6836666981379191\n",
      "0.6782299606005351\n",
      "0.6793849643071491\n",
      "0.6884123639265697\n",
      "0.6772475266456603\n",
      "0.6765178402264912\n",
      "0.6751298622290293\n",
      "0.6768537716070812\n",
      "0.6851858341693878\n",
      "0.6735738968849182\n",
      "0.6821114412943521\n",
      "0.6769849793116252\n",
      "0.6706606034437815\n",
      "0.674903666973114\n",
      "0.6665087751547495\n",
      "0.6698934630552927\n",
      "0.6700105202198028\n",
      "0.6736619436740875\n",
      "0.6550097382068635\n",
      "0.673731822570165\n",
      "0.66610573331515\n",
      "0.6697521408398946\n",
      "0.6514980049928029\n",
      "0.6638546144962311\n",
      "0.6637273021539052\n",
      "0.6683475406964621\n",
      "0.6603109065691629\n",
      "0.6626134618123373\n",
      "0.6415741201241811\n",
      "0.6477873333295187\n",
      "0.6536644721031188\n",
      "0.6609416103363037\n",
      "0.6667945992946626\n",
      "0.6601404714584351\n",
      "0.6797151378790538\n",
      "0.6716426444053649\n",
      "0.6455409828821818\n",
      "0.6478106423219044\n",
      "0.6479673337936401\n",
      "0.6659614328543345\n",
      "0.6484967362880707\n",
      "0.6759073344866434\n",
      "0.6503018299738565\n",
      "0.6371643129984538\n",
      "0.6555819316705067\n",
      "0.6467720071474711\n",
      "0.6624465906620025\n",
      "0.6585318112373352\n",
      "0.6611302820841471\n",
      "0.6477604707082113\n",
      "0.633825121720632\n",
      "0.6508379391829172\n",
      "0.6596483286221821\n",
      "0.6421999164422353\n",
      "0.6341082255045573\n",
      "0.6441301822662354\n",
      "0.6401122725009918\n",
      "0.6484798240661621\n",
      "0.6510581700007121\n",
      "0.6291448056697845\n",
      "0.6464171437422435\n",
      "0.6385284209251404\n",
      "0.6245285348097483\n",
      "0.633934985001882\n",
      "0.6250090233484903\n",
      "0.6354222758611043\n",
      "0.6514044523239134\n",
      "0.6274470456441245\n",
      "0.6372440044085185\n",
      "0.6458134178320567\n",
      "0.622229365905126\n",
      "0.6588422099749247\n",
      "0.6491459878285726\n",
      "0.6517537653446197\n",
      "0.6293863383928935\n",
      "0.6302453688780466\n",
      "0.6232788689931233\n",
      "0.6241258565584819\n",
      "0.6357829221089681\n",
      "0.622448968887329\n",
      "0.6572382839520773\n",
      "0.619871331055959\n",
      "0.6077439391613007\n",
      "0.628676969607671\n",
      "0.6337537368138632\n",
      "0.6243393814563751\n",
      "0.6170278251171112\n",
      "0.6229477298259735\n",
      "0.6464588904380798\n",
      "0.6280723245938619\n",
      "0.6113958509763081\n",
      "0.640882134437561\n",
      "0.6072528851032257\n",
      "0.6135055617491405\n",
      "0.6263251543045044\n",
      "0.6174138816197714\n",
      "0.6153700304031372\n",
      "0.6019859373569488\n",
      "0.6015761586030325\n",
      "0.6169389394919077\n",
      "0.621140391031901\n",
      "0.6190709499518077\n",
      "0.5958917971452077\n",
      "0.6121044246355692\n",
      "0.6255294231573739\n",
      "0.6086328415075938\n",
      "0.5814463353157043\n",
      "0.6509167496363322\n",
      "0.6575020905335744\n",
      "0.6158532003561656\n",
      "0.6164631481965382\n",
      "0.6337520857652028\n",
      "0.6469943885008494\n",
      "0.6160713469982148\n",
      "0.6298153591156006\n",
      "0.6392025399208069\n",
      "0.6404429753621419\n",
      "0.6270577998956045\n",
      "0.5958655301729837\n",
      "0.6139635229110718\n",
      "0.6115494767824808\n",
      "0.6122268370787302\n",
      "0.6024162781238557\n",
      "0.6157569682598115\n",
      "0.5980022478103638\n",
      "0.6125179680188497\n",
      "0.6197366174062093\n",
      "0.6252155963579814\n",
      "0.610680920680364\n",
      "0.6113365749518076\n",
      "0.586923070748647\n",
      "0.5941871392726897\n",
      "0.611791619459788\n",
      "0.601313161055247\n",
      "0.6290285579363505\n",
      "0.5900507934888204\n",
      "0.5881375928719839\n",
      "0.6097032554944356\n",
      "0.5819196077187856\n",
      "0.5898284908135732\n",
      "0.5764044785499572\n",
      "0.6024978673458099\n",
      "0.6205890293916067\n",
      "0.5565261014302572\n",
      "0.6186691534519195\n",
      "0.5969831053415935\n",
      "0.5808645331859589\n",
      "0.5640739266077678\n",
      "0.589017216761907\n",
      "0.5910121603806813\n",
      "0.5680173110961914\n",
      "0.55130601922671\n",
      "0.6230031156539916\n",
      "0.6191210158665975\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/azureuser/cloudfiles/code/FF/mnist.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f63326265373765662d633166322d346533622d393938352d6531633837656362303230352f7265736f7572636547726f7570732f6d792d67726f75702f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f466f7277617264466f72776172642f636f6d70757465732f6573736578/home/azureuser/cloudfiles/code/FF/mnist.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x_neg, _ \u001b[39m=\u001b[39m MNIST\u001b[39m.\u001b[39moverlay_y_on_x(x, y[rnd])\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f63326265373765662d633166322d346533622d393938352d6531633837656362303230352f7265736f7572636547726f7570732f6d792d67726f75702f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f466f7277617264466f72776172642f636f6d70757465732f6573736578/home/azureuser/cloudfiles/code/FF/mnist.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#print(x_pos.requires_grad, x_neg.requires_grad)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f63326265373765662d633166322d346533622d393938352d6531633837656362303230352f7265736f7572636547726f7570732f6d792d67726f75702f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f466f7277617264466f72776172642f636f6d70757465732f6573736578/home/azureuser/cloudfiles/code/FF/mnist.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m losses \u001b[39m=\u001b[39m model(x_pos, x_neg)\n\u001b[1;32m      <a href='vscode-notebook-cell://amlext%2B2f737562736372697074696f6e732f63326265373765662d633166322d346533622d393938352d6531633837656362303230352f7265736f7572636547726f7570732f6d792d67726f75702f70726f7669646572732f4d6963726f736f66742e4d616368696e654c6561726e696e6753657276696365732f776f726b7370616365732f466f7277617264466f72776172642f636f6d70757465732f6573736578/home/azureuser/cloudfiles/code/FF/mnist.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(losses)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/essex/code/FF/ff.py:87\u001b[0m, in \u001b[0;36mFF.forward\u001b[0;34m(self, x_pos, x_neg)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall(x_pos)\n\u001b[1;32m     86\u001b[0m \u001b[39mfor\u001b[39;00m i, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m---> 87\u001b[0m     x_pos, x_neg, loss \u001b[39m=\u001b[39m layer(x_pos, x_neg)\n\u001b[1;32m     88\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss)\n\u001b[1;32m     89\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mmean(losses)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/essex/code/FF/ff.py:49\u001b[0m, in \u001b[0;36mFFLayer.forward\u001b[0;34m(self, x_pos, x_neg)\u001b[0m\n\u001b[1;32m     46\u001b[0m     loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlog(\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39mexp(\n\u001b[1;32m     47\u001b[0m         torch\u001b[39m.\u001b[39mcat([\u001b[39m-\u001b[39mpos_good \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold, neg_good \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold])))\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     48\u001b[0m     losses\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> 49\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m \u001b[39m# disable gradient calculation to allow the result to be passed to the next layer\u001b[39;00m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i, (x, y) in enumerate(train_loader):\n",
    "    x_pos, _ = MNIST.overlay_y_on_x(x, y)\n",
    "    rnd = torch.randperm(x.size(0))\n",
    "    x_neg, _ = MNIST.overlay_y_on_x(x, y[rnd])\n",
    "    #print(x_pos.requires_grad, x_neg.requires_grad)\n",
    "    losses = model(x_pos, x_neg)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55f647d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ww/jr0958_14cn18kjs05m9k57c0000gq/T/ipykernel_21385/3261064448.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/FF/data.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(data_loader, model)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverlay_y_on_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "predictions, real = MNIST.predict(test_loader, model)\n",
    "print(\"Accuracy \", np.sum(predictions == real)/len(real))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
