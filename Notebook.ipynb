{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Sleep Deprivation FF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from FF import FF\n",
    "from data import CIFAR10, MNIST, FMNIST, MergedDataset\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 512 # This batch size was used for the paper but a larger batch size might be beneficial for normal use.\n",
    "batch_size_test = 10_000\n",
    "base_dataset = FMNIST # This can be changed to CIFAR10, MNIST, or FMNIST\n",
    "negative_data_with_masks_iteration = 5 # Number of convolution steps to apply to negative data masks.\n",
    "\n",
    "# This caches the datasets in memory to speed up training.\n",
    "train_dataset = base_dataset.get_in_memory(train=True)\n",
    "train_negative_dataset = base_dataset.get_in_memory(train=True)\n",
    "test_dataset = base_dataset.get_in_memory(train=False)\n",
    "\n",
    "# Loaders for train and test data\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size_test, shuffle=False)\n",
    "\n",
    "# Loader for masked negative data( has batch size of 1 to batch the mask application process )\n",
    "train_loader_negative = torch.utils.data.DataLoader(MergedDataset(train_negative_dataset, negative_data_with_masks_iteration, batch_size_train, base_dataset.negative_data_with_masks), batch_size=1, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing some of the images of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# show images\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(images[:4], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()\n",
    "\n",
    "# print labels\n",
    "print(' '.join('%5s' % labels[j].item() for j in range(4)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing how an overlayed image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(train_loader))[0][0]\n",
    "image = base_dataset.overlay_y_on_x(image, 1)[0].reshape(base_dataset.get_image_shape())\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing how a negative data image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(train_loader_negative))[0].cpu()\n",
    "image = image.reshape((-1, *base_dataset.get_image_shape()))[0]\n",
    "plt.imshow(np.transpose(image, (1, 2, 0)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set all parameters and create the model.\n",
    "It uses an architecture of \n",
    "input_size -> 500 -> 500 -> 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1.5\n",
    "epochs_per_layer = 50 # Represents how many updates per batch of training data a layer will get.\n",
    "\n",
    "awake_period = 1 # The period that the model will be awake for. Setting it to -1 will make the model act without phase separation.\n",
    "sleep_period = 1 # The period that the model will be asleep for.\n",
    "\n",
    "assert awake_period > 0 or awake_period == -1, \"awake_period must be greater than 0 or -1\"\n",
    "assert sleep_period > 0, \"sleep_period must be greater than 0\"\n",
    "\n",
    "optim_lr = 0.001 # The learning rate for the optimizer when awake_period is set to -1.\n",
    "positive_lr = 0.001 / awake_period # The learning rate for the optimizer when awake_period is set to a positive value, it will be divided by the awake_period as to scale the learning rate down.\n",
    "\n",
    "negative_lr = 0.001 # The learning rate for the negative forward pass optimizer.\n",
    "\n",
    "epochs = 500\n",
    "hour = 0 # The figurative hour of the day that the model will start on. This is used to determine the phase of the model.\n",
    "print_every = 1\n",
    "with_masks = True # Toggles between using masks and not using masks.\n",
    "\n",
    "model = FF(device=device)\n",
    "model.to(device)\n",
    "\n",
    "# 3 layers of 500 neurons each\n",
    "model.add_layer(np.prod(base_dataset.get_image_shape()), 500, optim_lr, positive_lr, negative_lr, threshold, epochs_per_layer)\n",
    "model.add_layer(500, 500, optim_lr, positive_lr, negative_lr, threshold, epochs_per_layer)\n",
    "model.add_layer(500, 500, optim_lr, positive_lr, negative_lr, threshold, epochs_per_layer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_number_besides(x):\n",
    "    \"\"\"Returns a random number between 0 and 9 that is not x\"\"\"\n",
    "    num = random.randint(0,9)\n",
    "    if num==x: return get_random_number_besides(x)\n",
    "    return num\n",
    "\n",
    "def get_negative_y(y):\n",
    "    \"\"\"Returns a tensor of the same shape as y but with random numbers between 0 and 9 that are not the same as y\"\"\"\n",
    "    return torch.tensor([get_random_number_besides(i) for i in y], dtype = torch.long).to(device)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for i in tqdm(range(epochs), desc=\"Epochs\"):\n",
    "\n",
    "    # Prints every print_every epochs\n",
    "    if i % print_every == 0:\n",
    "        \n",
    "        predictions, real = base_dataset.predict(test_loader, model, device)\n",
    "        acc = np.sum(predictions == real)/len(real)\n",
    "        print(\"Accuracy on test data: \", acc)\n",
    "        accuracies.append(acc)\n",
    "        \n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    if with_masks:\n",
    "        \n",
    "        for a, b in zip(enumerate(train_loader), enumerate(train_loader_negative)):\n",
    "            x_pos = a[1][0].to(device)\n",
    "            y = a[1][1].to(device)\n",
    "            x_neg = b[1].reshape(batch_size_train, -1)\n",
    "            if awake_period == -1:\n",
    "              x_pos,_ = base_dataset.overlay_y_on_x(x_pos, y)\n",
    "              x_neg,_ = base_dataset.overlay_y_on_x(x_neg, get_negative_y(y))\n",
    "              a = model.forward(x_pos, x_neg)\n",
    "            else:\n",
    "              if hour % (awake_period + sleep_period) < awake_period:\n",
    "                  x_pos,_ = base_dataset.overlay_y_on_x(x_pos, y)\n",
    "                  loss = model.forward_positive(x_pos)\n",
    "              else:\n",
    "                  x_neg,_ = base_dataset.overlay_y_on_x(x_neg, get_negative_y(y))\n",
    "                  loss = model.forward_negative(x_neg)\n",
    "            hour += 1\n",
    "    else:\n",
    "\n",
    "        for a in enumerate(train_loader):\n",
    "            x_pos = a[1][0].to(device)\n",
    "            y = a[1][1].to(device)\n",
    "            if awake_period == -1:\n",
    "                x_pos,_ = base_dataset.overlay_y_on_x(x_pos, y)\n",
    "                x_neg,_ = base_dataset.overlay_y_on_x(x_pos.clone(), get_negative_y(y))\n",
    "                model.forward(x_pos, x_neg)\n",
    "            else:\n",
    "              if hour % (awake_period + sleep_period) < awake_period:\n",
    "                  x_pos,_ = base_dataset.overlay_y_on_x(x_pos, y)\n",
    "                  model.forward_positive(x_pos)\n",
    "              else:\n",
    "                  x_neg,_ = base_dataset.overlay_y_on_x(x_pos, get_negative_y(y))\n",
    "                  model.forward_negative(x_neg)\n",
    "            hour += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the test accuracy history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Test accuracy of the model over time\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
