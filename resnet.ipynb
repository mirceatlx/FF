{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rdyt2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import wandb\n",
    "from ff import FF, FFLayer, FFEncoder\n",
    "from data import MNIST, MergedDataset, CIFAR10\n",
    "from tqdm import tqdm\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "# Define transforms for the dataset\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./datasets/MNIST/', train=True, transform=transform_train, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./datasets/MNIST/', train=False, transform=transform_test, download=True)\n",
    "\n",
    "# Create data loaders for the dataset\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "# Load the ResNet-50 model\n",
    "resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_out = resnet.fc.in_features\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "resnet = resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_error = lambda x: x.pow(2).mean(1)\n",
    "deviation_error = lambda x: -((x - x.mean(1).unsqueeze(1)).pow(2).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "threshold = 1.5\n",
    "epochs_per_layer = 50\n",
    "model = FF(logging=False, device=device)\n",
    "optim_config = {\n",
    "    \"lr\": 0.01,\n",
    "}\n",
    "positive_optim_config = {\n",
    "    \"lr\": 0.001,\n",
    "\n",
    "}\n",
    "negative_optim_config = {\n",
    "    \"lr\": 0.001,\n",
    "}\n",
    "\n",
    "goodness_function = squared_error\n",
    "awake_period = 1\n",
    "sleep_period = 1\n",
    "print(num_out)\n",
    "model.add_layer(FFLayer(nn.Linear(1_000, 1_000).to(device), optimizer=torch.optim.Adam, epochs=epochs_per_layer, threshold=threshold, activation=nn.ReLU(), optim_config=optim_config, positive_optim_config=positive_optim_config, negative_optim_config=negative_optim_config, logging=False, name=\"layer 1\", device = device, goodness_function=goodness_function).to(device))\n",
    "model.add_layer(FFLayer(nn.Linear(1_000, 1_000).to(device), optimizer=torch.optim.Adam, epochs=epochs_per_layer, threshold=threshold, activation=nn.ReLU(), optim_config=optim_config, positive_optim_config=positive_optim_config, negative_optim_config=negative_optim_config, logging=False, name=\"layer 2\", device = device, goodness_function=goodness_function).to(device))\n",
    "model.add_layer(FFLayer(nn.Linear(1_000, 1_000).to(device), optimizer=torch.optim.Adam, epochs=epochs_per_layer, threshold=threshold, activation=nn.ReLU(), optim_config=optim_config, positive_optim_config=positive_optim_config, negative_optim_config=negative_optim_config, logging=False, name=\"layer 3\", device = device, goodness_function=goodness_function).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [03:26,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1223\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for _, (x, y) in tqdm(enumerate(train_loader)):\n",
    "    x_pos, _ = CIFAR10.overlay_y_on_x(x, y)\n",
    "    rnd = torch.randperm(x.size(0))\n",
    "    x_pos = x_pos.reshape((-1, 3, 224, 224))\n",
    "    x_neg, _ = CIFAR10.overlay_y_on_x(x, y[rnd])\n",
    "    x_pos, x_neg = x_pos.to(device), x_neg.to(device)\n",
    "    x_neg = x_neg.reshape((-1, 3, 224, 224))\n",
    "    x_pos = resnet(x_pos)\n",
    "    x_neg = resnet(x_neg)\n",
    "    model.forward(x_pos, x_neg)\n",
    "\n",
    "model.eval()\n",
    "predictions, real = CIFAR10.predict_resnet(test_loader, model, resnet, device)\n",
    "acc = np.sum(predictions == real)/len(real)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrd211\u001b[0m (\u001b[33mffalgo\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\rdyt2\\Desktop\\FF\\wandb\\run-20230219_142206-k2d8jnkc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ffalgo/CIFAR/runs/k2d8jnkc' target=\"_blank\">resnet-pretrained-simple-cifar</a></strong> to <a href='https://wandb.ai/ffalgo/CIFAR' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ffalgo/CIFAR' target=\"_blank\">https://wandb.ai/ffalgo/CIFAR</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ffalgo/CIFAR/runs/k2d8jnkc' target=\"_blank\">https://wandb.ai/ffalgo/CIFAR/runs/k2d8jnkc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"CIFAR\", entity=\"ffalgo\", name=\"resnet-pretrained-simple-cifar\")\n",
    "wandb.config = {\n",
    "  \"learning_rate\": 0.01,\n",
    "  \"awake_period\": awake_period,\n",
    "  \"sleep_period\": sleep_period,\n",
    "  \"epochs_per_layer\": epochs_per_layer,\n",
    "  \"batch_size\": 512,\n",
    "  \"activation\": \"relu\",\n",
    "  \"positive_lr\": 0.0001,\n",
    "  \"negative_lr\": 0.0001,\n",
    "  \"threshold\": threshold,\n",
    "  \"optimizer\": torch.optim.Adam,\n",
    "  \"device\": device\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [21:44<35:52:35, 1304.60s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m     acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(predictions \u001b[39m==\u001b[39m real)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(real)\n\u001b[0;32m      6\u001b[0m     wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mAccuracy on test data\u001b[39m\u001b[39m\"\u001b[39m: acc})\n\u001b[1;32m----> 8\u001b[0m predictions, real \u001b[39m=\u001b[39m CIFAR10\u001b[39m.\u001b[39;49mpredict_resnet(train_loader, model, resnet, device)\n\u001b[0;32m      9\u001b[0m acc \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(predictions \u001b[39m==\u001b[39m real)\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(real)\n\u001b[0;32m     10\u001b[0m wandb\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mAccuracy on train data\u001b[39m\u001b[39m\"\u001b[39m: acc})\n",
      "File \u001b[1;32mc:\\Users\\rdyt2\\Desktop\\FF\\data.py:53\u001b[0m, in \u001b[0;36mCIFAR10.predict_resnet\u001b[1;34m(data_loader, model, resnet, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m     over_x \u001b[39m=\u001b[39m resnet(over_x\u001b[39m.\u001b[39mto(device))\n\u001b[0;32m     52\u001b[0m     over_x \u001b[39m=\u001b[39m over_x\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m---> 53\u001b[0m     good \u001b[39m=\u001b[39m model(over_x)\n\u001b[0;32m     54\u001b[0m     goodness\u001b[39m.\u001b[39mappend(good\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[0;32m     55\u001b[0m goodness \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(goodness)\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\rdyt2\\Desktop\\FF\\ff.py:152\u001b[0m, in \u001b[0;36mFF.forward\u001b[1;34m(self, x_pos, x_neg)\u001b[0m\n\u001b[0;32m    150\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m    151\u001b[0m \u001b[39mif\u001b[39;00m x_neg \u001b[39m==\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(x_pos)\n\u001b[0;32m    154\u001b[0m \u001b[39mfor\u001b[39;00m _, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m    155\u001b[0m     x_pos, x_neg, loss \u001b[39m=\u001b[39m layer(x_pos, x_neg)\n",
      "File \u001b[1;32mc:\\Users\\rdyt2\\Desktop\\FF\\ff.py:168\u001b[0m, in \u001b[0;36mFF.call\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m    165\u001b[0m \u001b[39m   \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[39m   Calculate the total goodness of the network for some data (positive/negative)\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[39m   \"\"\"\u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m    goodness \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(x\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m])\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m    169\u001b[0m    \u001b[39mfor\u001b[39;00m i, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m    170\u001b[0m        x \u001b[39m=\u001b[39m layer(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for i in tqdm(range(epochs)):\n",
    "    if i % 1 == 0:\n",
    "        predictions, real = CIFAR10.predict_resnet(test_loader, model, resnet, device)\n",
    "        acc = np.sum(predictions == real)/len(real)\n",
    "        wandb.log({\"Accuracy on test data\": acc})\n",
    "        \n",
    "    predictions, real = CIFAR10.predict_resnet(train_loader, model, resnet, device)\n",
    "    acc = np.sum(predictions == real)/len(real)\n",
    "    wandb.log({\"Accuracy on train data\": acc})\n",
    "    model.train()\n",
    "    for _, (x, y) in enumerate(train_loader):\n",
    "        x_pos, _ = CIFAR10.overlay_y_on_x(x, y)\n",
    "        x_pos = x_pos.reshape((-1, 3, 224, 224))\n",
    "        rnd = torch.randperm(x.size(0))\n",
    "        x_neg, _ = CIFAR10.overlay_y_on_x(x, y[rnd])\n",
    "        x_neg = x_neg.reshape((-1, 3, 224, 224))\n",
    "        x_pos, x_neg = x_pos.to(device), x_neg.to(device)\n",
    "        x_pos = resnet(x_pos)\n",
    "        x_neg = resnet(x_neg)\n",
    "        model.forward(x_pos, x_neg)\n",
    "        \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6f8d400343bb3f57bd29c3eb1404dce9b47f9b5dee6203cb0f40ad0e600826b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
