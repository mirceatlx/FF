{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bd5542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from data import CIFAR10\n",
    "from ff import FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764275e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cfdc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4cd4d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a894df7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87d436b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./datasets', train=False,\n",
    "                                       download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee61a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119c9497",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6eb7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"in_dims\": [3468, 3468, 3468],\n",
    "    \"out_dims\": [3468, 3468, 3468],\n",
    "    \"epochs\": 25,\n",
    "    \"threshold\": 2\n",
    "}\n",
    "num_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2cc54b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "874e0284",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FF(num_layers, config, torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef3c833b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FF()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b33d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10dac873",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5483bf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x, new_y = CIFAR10.overlay_y_on_x(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ce6aa96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3072])\n",
      "tensor([0.0001, 0.0001, 0.0001, 0.0001], grad_fn=<MeanBackward1>)\n",
      "torch.Size([4, 3072])\n",
      "tensor([0.0001, 0.0001, 0.0001, 0.0001], grad_fn=<MeanBackward1>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0002, 0.0002, 0.0002, 0.0002], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(new_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3400d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "472887f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True,\n",
    "                                        download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa20358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e413f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7862356456120808\n",
      "0.7092948150634765\n",
      "0.701378071308136\n",
      "0.6984734988212585\n",
      "0.6936511484781901\n",
      "0.6910433030128479\n",
      "0.6941611536343893\n",
      "0.6899163309733073\n",
      "0.6888981310526531\n",
      "0.6929790989557901\n",
      "0.6811924934387207\n",
      "0.6801064546902976\n",
      "0.6773826670646667\n",
      "0.6730228487650555\n",
      "0.6700795896848043\n",
      "0.6708218423525492\n",
      "0.6707312099138895\n",
      "0.6635757700602214\n",
      "0.6626875178019206\n",
      "0.6598532199859619\n",
      "0.6933364168802897\n",
      "0.6710074774424234\n",
      "0.6535877641042074\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i, (x, y) in enumerate(trainloader):\n",
    "    \n",
    "    x_pos, _ =  CIFAR10.overlay_y_on_x(x, y)\n",
    "    rnd = torch.randperm(x.size(0))\n",
    "    x_neg, _ = CIFAR10.overlay_y_on_x(x, y[rnd])\n",
    "    losses = model(x_pos, x_neg)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053f0e75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
